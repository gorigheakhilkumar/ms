{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sofsHfTguYWj",
        "outputId": "a48f64f8-59ce-4b89-b1d8-e031f64a5e40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bioinfokit\n",
            "  Using cached bioinfokit-2.1.0-py3-none-any.whl\n",
            "Collecting textwrap3\n",
            "  Using cached textwrap3-0.9.2-py2.py3-none-any.whl (12 kB)\n",
            "Collecting adjustText\n",
            "  Using cached adjustText-0.7.3-py3-none-any.whl\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from bioinfokit) (0.8.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from bioinfokit) (1.3.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from bioinfokit) (1.7.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (from bioinfokit) (0.11.2)\n",
            "Requirement already satisfied: matplotlib-venn in /usr/local/lib/python3.8/dist-packages (from bioinfokit) (0.11.7)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.8/dist-packages (from bioinfokit) (0.12.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from bioinfokit) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from bioinfokit) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from bioinfokit) (1.0.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bioinfokit) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bioinfokit) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bioinfokit) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bioinfokit) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->bioinfokit) (2022.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->bioinfokit) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->bioinfokit) (1.2.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/dist-packages (from statsmodels->bioinfokit) (0.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5->statsmodels->bioinfokit) (1.15.0)\n",
            "Installing collected packages: textwrap3, adjustText, bioinfokit\n",
            "Successfully installed adjustText-0.7.3 bioinfokit-2.1.0 textwrap3-0.9.2\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install bioinfokit\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"../input/mcdonalds/mcdonalds.csv\")\n",
        "df.shape\n",
        "df.head()\n",
        "df.dtypes\n",
        "df.info()\n",
        "df.isnull().sum()\n",
        "df['Gender'].value_counts()\n",
        "df['VisitFrequency'].value_counts()\n",
        "df['Like'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "d7Z6_nqcumaV",
        "outputId": "ec4789e6-8a08-4183-e005-9eb448e38603"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-819bb586cf74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/mcdonalds/mcdonalds.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/mcdonalds/mcdonalds.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['Female', 'Male']\n",
        "size = df['Gender'].value_counts()\n",
        "colors = ['pink', 'cyan']\n",
        "explode = [0, 0.1]\n",
        "plt.rcParams['figure.figsize'] = (7, 7)\n",
        "plt.pie(size, colors = colors, explode = explode, labels = labels, shadow = True, autopct = '%.2f%%')\n",
        "plt.title('Gender', fontsize = 20)\n",
        "plt.axis('off')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.rcParams['figure.figsize'] = (25, 8)\n",
        "f = sns.countplot(x=df['Age'],palette = 'hsv')\n",
        "f.bar_label(f.containers[0])\n",
        "plt.title('Age distribution of customers')\n",
        "plt.show()\n",
        "df['Like']= df['Like'].replace({'I hate it!-5': '-5','I love it!+5':'+5'})\n",
        "#Like \n",
        "sns.catplot(x=\"Like\", y=\"Age\",data=df, \n",
        "            orient=\"v\", height=5, aspect=2, palette=\"Set2\",kind=\"swarm\")\n",
        "plt.title('Likelyness of McDonald w.r.t Age')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Aix7QSWLuyHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "def labelling(x):\n",
        "    df[x] = LabelEncoder().fit_transform(df[x])\n",
        "    return df\n",
        "​\n",
        "cat = ['yummy', 'convenient', 'spicy', 'fattening', 'greasy', 'fast', 'cheap',\n",
        "       'tasty', 'expensive', 'healthy', 'disgusting']\n",
        "​\n",
        "for i in cat:\n",
        "    labelling(i)\n",
        "df\n",
        "\n",
        "#Histogram of the each attributes\n",
        "plt.rcParams['figure.figsize'] = (12,14)\n",
        "df.hist()\n",
        "plt.show()\n",
        "add Codeadd Markdown\n",
        "#Considering only first 11 attributes\n",
        "df_eleven = df.loc[:,cat]\n",
        "df_eleven\n",
        "\n",
        "#Considering only the 11 cols and converting it into array\n",
        "x = df.loc[:,cat].values\n",
        "x\n",
        "\n",
        "#Principal component analysis\n",
        "​\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import preprocessing\n",
        "​\n",
        "pca_data = preprocessing.scale(x)\n",
        "​\n",
        "pca = PCA(n_components=11)\n",
        "pc = pca.fit_transform(x)\n",
        "names = ['pc1','pc2','pc3','pc4','pc5','pc6','pc7','pc8','pc9','pc10','pc11']\n",
        "pf = pd.DataFrame(data = pc, columns = names)\n",
        "pf\n",
        "​\n",
        "\n",
        "#Proportion of Variance (from PC1 to PC11)\n",
        "pca.explained_variance_ratio_\n",
        "add Codeadd Markdown\n",
        "np.cumsum(pca.explained_variance_ratio_)\n",
        "add Codeadd Markdown\n",
        "# correlation coefficient between original variables and the component\n",
        "​\n",
        "loadings = pca.components_\n",
        "num_pc = pca.n_features_\n",
        "pc_list = [\"PC\"+str(i) for i in list(range(1, num_pc+1))]\n",
        "loadings_df = pd.DataFrame.from_dict(dict(zip(pc_list, loadings)))\n",
        "loadings_df['variable'] = df_eleven.columns.values\n",
        "loadings_df = loadings_df.set_index('variable')\n",
        "loadings_df\n",
        "\n",
        "#Correlation matrix plot for loadings \n",
        "plt.rcParams['figure.figsize'] = (20,15)\n",
        "ax = sns.heatmap(loadings_df, annot=True, cmap='Spectral')\n",
        "plt.show()\n",
        "\n",
        "#Scree plot (Elbow test)- PCA\n",
        "from bioinfokit.visuz import cluster\n",
        "cluster.screeplot(obj=[pc_list, pca.explained_variance_ratio_],show=True,dim=(10,5))\n",
        "\n",
        "# get PC scores\n",
        "pca_scores = PCA().fit_transform(x)\n",
        "​\n",
        "# get 2D biplot\n",
        "cluster.biplot(cscore=pca_scores, loadings=loadings, labels=df.columns.values, var1=round(pca.explained_variance_ratio_[0]*100, 2),\n",
        "    var2=round(pca.explained_variance_ratio_[1]*100, 2),show=True,dim=(10,5))\n",
        "add Codeadd Markdown\n",
        "EXTRACTING SEGMENTS\n",
        "\n",
        "\n",
        "#Extracting segments\n",
        "​\n",
        "#Using k-means clustering analysis\n",
        "from sklearn.cluster import KMeans\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "model = KMeans()\n",
        "visualizer = KElbowVisualizer(model, k=(1,12)).fit(df_eleven)\n",
        "visualizer.show()\n",
        "add Codeadd Markdown\n",
        "#K-means clustering \n",
        "​\n",
        "kmeans = KMeans(n_clusters=4, init='k-means++', random_state=0).fit(df_eleven)\n",
        "df['cluster_num'] = kmeans.labels_ #adding to df\n",
        "print (kmeans.labels_) #Label assigned for each data point\n",
        "print (kmeans.inertia_) #gives within-cluster sum of squares. \n",
        "print(kmeans.n_iter_) #number of iterations that k-means algorithm runs to get a minimum within-cluster sum of squares\n",
        "print(kmeans.cluster_centers_) #Location of the centroids on each cluster. \n",
        "add Codeadd Markdown\n",
        "#To see each cluster size\n",
        "from collections import Counter\n",
        "Counter(kmeans.labels_)\n",
        "\n",
        "#Visulazing clusters\n",
        "sns.scatterplot(data=pf, x=\"pc1\", y=\"pc2\", hue=kmeans.labels_)\n",
        "plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], \n",
        "            marker=\"X\", c=\"r\", s=80, label=\"centroids\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "DESCRIBING SEGMENTS\n",
        "\n",
        "\n",
        "#DESCRIBING SEGMENTS\n",
        "from statsmodels.graphics.mosaicplot import mosaic\n",
        "from itertools import product\n",
        "​\n",
        "crosstab =pd.crosstab(df['cluster_num'],df['Like'])\n",
        "#Reordering cols\n",
        "crosstab = crosstab[['-5','-4','-3','-2','-1','0','+1','+2','+3','+4','+5']]\n",
        "crosstab \n",
        "\n",
        "#MOSAIC PLOT\n",
        "plt.rcParams['figure.figsize'] = (7,5)\n",
        "mosaic(crosstab.stack())\n",
        "plt.show()\n",
        "\n",
        "#Mosaic plot gender vs segment\n",
        "crosstab_gender =pd.crosstab(df['cluster_num'],df['Gender'])\n",
        "crosstab_gender\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (7,5)\n",
        "mosaic(crosstab_gender.stack())\n",
        "plt.show()\n",
        "\n",
        "#box plot for age\n",
        "​\n",
        "sns.boxplot(x=\"cluster_num\", y=\"Age\", data=df)\n",
        "​\n",
        "\n",
        "Selecting target segment\n",
        "\n",
        "\n",
        "#Calculating the mean\n",
        "#Visit frequency\n",
        "df['VisitFrequency'] = LabelEncoder().fit_transform(df['VisitFrequency'])\n",
        "visit = df.groupby('cluster_num')['VisitFrequency'].mean()\n",
        "visit = visit.to_frame().reset_index()\n",
        "visit\n",
        "\n",
        "#Like\n",
        "df['Like'] = LabelEncoder().fit_transform(df['Like'])\n",
        "Like = df.groupby('cluster_num')['Like'].mean()\n",
        "Like = Like.to_frame().reset_index()\n",
        "Like\n",
        "\n",
        "#Gender\n",
        "df['Gender'] = LabelEncoder().fit_transform(df['Gender'])\n",
        "Gender = df.groupby('cluster_num')['Gender'].mean()\n",
        "Gender = Gender.to_frame().reset_index()\n",
        "Gender\n",
        "\n",
        "segment = Gender.merge(Like, on='cluster_num', how='left').merge(visit, on='cluster_num', how='left')\n",
        "segment\n",
        "\n",
        "#Target segments\n",
        "​\n",
        "plt.figure(figsize = (9,4))\n",
        "sns.scatterplot(x = \"VisitFrequency\", y = \"Like\",data=segment,s=400, color=\"r\")\n",
        "plt.title(\"Simple segment evaluation plot for the fast food data set\",\n",
        "          fontsize = 15) \n",
        "plt.xlabel(\"Visit\", fontsize = 12) \n",
        "plt.ylabel(\"Like\", fontsize = 12) \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QNEB0bPhvs1b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}